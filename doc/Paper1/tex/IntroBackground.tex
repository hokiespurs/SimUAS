\section{Introduction}

Three dimensional Geospatial pointcloud data with an accuracy $<$5cm and with a density greater than 10 points/m$^2$ has traditionally been acquired using either terrestrial or airborne lidar, but recent advances in Structure from Motion and MultiView Stereo algorithms have increased in popularity within the past 10 years.  SFM and MVS algorithms began development 30+ years ago (site\todocite{cite: OLD SFM-MVS}) but have only begun to be utilized for commercial surveying applications recently due to the advances in camera hardware, Unmanned Aerial Systems (UAS), computer processing power, and commercial SFM-MVS software.  Research into SFM and MVS in the geomatics community is currently focused on both the accuracy and potential applications of the commercial SFM and MVS software packages such as Agisoft Photoscan and Pix4d \todocite{cite: Geomprph sfm paper}.  The accuracy of SFM-MVS can vary greatly depending on a variety of factors \todocite{cite: accuracy vs factors}, and the geomatics community is currently focused on determining potential use cases where SFM-MVS derived pointclouds can begin to replace lidar as an alternative surveying tool, without sacrificing accuracy.  \todo{Should I cite specific use examples?}.  The most common methodology for assessing the use cases and accuracy of SFM-MVS algorithms is to collect data in the field using a UAS and compare the data to lidar data.  It is difficult to constrain many of the independent variables using this methodology, and the data acquisition can be expensive and time consuming.  We propose a computer graphics based workflow to simulate various scenes and maintain full control over the ground-truth and the camera parameters.  This workflow will allow for more robust experiments to be performed by geomatics engineers to assess the feasibility and accuracy of SFM-MVS in various applications.

The 3D reconstruction methods used in most commercial software consist of an SFM algorithm first, then an MVS algorithm.  Unordered photographs are input into the software, and a keypoint detection algorithm such as SIFT\todocite{cite sift} is used to detect keypoints and correspondences between images.  The SFM algorithm calculates camera interior orientation, exterior orientation, and a "sparse" pointcloud.  A bundle adjustment is performed to optimize the matches.  Without any additional information, the coordinate system is arbitrary.  Either the camera position for each camera, or ground control points are used to transform the coordinate system.  This transformation can either be done with a helmert transform, \todocite{cite: helmert uas} or using a nonlinear optimization.  The interior and exterior orientation for each image is used as the input to the MVS algorithm, which generates a more dense pointcloud.  The MVS algorithm can generate more correspondences because it utilizes a 1D search along the epipolar line between two images due to the known interior and exterior orientation.  For this reason, the accuracy of the MVS algorithm is highly dependent on the accuracy of the parameters calculated with the SFM algorithm.  A detailed explanation of the various MVS algorithms can be found in paper\todocite{cite MVS algorithms}.  Each of these algorithms also assumes that the scene is rigid with constant lambertian surfaces, and deviations from these assumptions will drastically effect the accuracy. 

Numerous studies have been performed to quantify the accuracy of the SFM-MVS algorithms in a variety of environments\todocite{cite lidar accuracy studies}.  The most common and robust method has been to compare the SFM-MVS derived pointcloud to a groundtruth terrestrial lidar survey \todocite{cite: sfm vs lidar}.  Independent GPS control points have also been used, but result in fewer correspondences to compare with \todocite{cite: sfm vs independent gcps}.  The use of independent control points also can exhibit a bias when the points used are easily photo identifiable targets (eg. checkerboards).  The highly textured independent control points will demonstrate a much better accuracy than a homogeneous surface, due to the lack of matching features, and therefore are not necessarily representative of the accuracy of the entire scene.  The accuracy of SFM is adversely affected by: homogeneous scene texture, poor image overlapping, lens distortion not modeled by the nonlinear lens distortion equation, poor GCP distribution, inaccurate GCP or Camera positions, poor image resolution, blurry imagery, noisy imagery, varying sun shadows, moving objects in the scene, user error in manually selecting image coordinates of GCPs, low number of images, or a low number of GCPs.  With a computer graphics workflow, each of these variables can be constrained and varied in order to assess the effect on the overall accuracy of the scene.  The accuracy of the resultant SFM-MVS pointcloud is also assessed by comparing it to a scene with no uncertainty because it is simulated.  

\section{Computer Graphics for Remote Sensing Analysis}
The field of computer graphics has been developed predominantly for video games and movies.  There are numerous settings when rendering a scene which will drastically alter the resultant rendering.
\todolong{Need to go into depth on each of these bullets.  Really need to expand this section.}
\begin{itemize}
	\item Ray-Tracing vs Radiosity and global vs local illumination.
	\item Antialiasing methodology.
	\item Texturing Objects.
\end{itemize}

More detailed information on the computer graphics pipeline is described in detail by someone \todocite{cite: computer graphics pipeline}.  

Utilizing computer generated imagery as a methodology to test theoretical concepts has been used to test someone and something. \todocite{cite dirsig}.  \todocite{cite other CGI for remote sensing}