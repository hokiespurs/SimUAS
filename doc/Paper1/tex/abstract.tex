\section*{Abstract}
Structure from Motion (SfM) and MultiView Stereo (MVS) algorithms are increasingly being used to generate pointcloud data for various surveying applications, however the accuracy and sources of error in the resultant pointcloud across various use cases are difficult to realize without thorough experimentation.  The acquisition of imagery and rigorous ground control data at field sites required for this experimentation is a time consuming and sometimes expensive endeavor.  These experiments are also almost always unable to be perfectly replicated due to the numerous uncontrollable independent variables, such as solar radiation, sun angle, cloud cover, wind, objects in the scene moving, exterior orientation of cameras, and camera noise to name a few.  The large number of independent variables creates a scenario where robust, repeatable experiments are cost prohibitive and the results are frequently site specific.  Here, we present a workflow to render computer generated imagery using a virtual environment which can mimic all the independent variables that would be experienced in a real-world data acquisition scenario.  The resultant modular workflow utilizes the open source software Blender for the generation of photogrammetrically accurate imagery suitable for SfM processing, with tight control on camera interior orientation, exterior orientation, texture of objects in the scene, placement of objects in the scene, and Ground Control Point (GCP) accuracy.  The challenges and steps required to validate the photogrammetric accuracy of computer generated imagery are discussed, and an example experiment assessing accuracy of an SFM derived pointcloud from imagery rendered using a computer graphics workflow is presented.